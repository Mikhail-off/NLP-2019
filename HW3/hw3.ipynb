{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3\n",
    "## Yes/No Questions\n",
    "\n",
    "deadline: 3 –¥–µ–∫–∞–±—Ä—è 2019, 23:59\n",
    "\n",
    "–í —ç—Ç–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤—ã –±—É–¥–µ—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∫–æ—Ä–ø—É—Å–æ–º BoolQ. –ö–æ—Ä–ø—É—Å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –≤–æ–ø—Ä–æ—Å–æ–≤, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—â–∏—Ö –±–∏–Ω–∞—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç (–¥–∞ / –Ω–µ—Ç), –∞–±–∑–∞—Ü–µ–≤ –∏–∑ –í–∏–∫–∏–ø–µ–¥–∏–∏,  —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç–∞—Ç—å–∏, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –∏–∑–≤–ª–µ—á–µ–Ω –∞–±–∑–∞—Ü –∏ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –æ—Ç–≤–µ—Ç–∞ (true / false).\n",
    "\n",
    "–ö–æ—Ä–ø—É—Å –æ–ø–∏—Å–∞–Ω –≤ —Å—Ç–∞—Ç—å–µ:\n",
    "\n",
    "Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova\n",
    "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions\n",
    "\n",
    "https://arxiv.org/abs/1905.10044\n",
    "\n",
    "\n",
    "–ö–æ—Ä–ø—É—Å (train-dev split) –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞:  https://github.com/google-research-datasets/boolean-questions\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è train —á–∞—Å—Ç—å –∫–æ—Ä–ø—É—Å–∞, –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äì dev —á–∞—Å—Ç—å. \n",
    "\n",
    "–ö–∞–∂–¥—ã–π –±–æ–Ω—É—Å –ø—É–Ω–∫—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—Å—è –≤ 1 –±–∞–ª–ª. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞: \n",
    "question: is batman and robin a sequel to batman forever\n",
    "\n",
    "title: Batman & Robin (film)\n",
    "\n",
    "answer: true\n",
    "\n",
    "passage: With the box office success of Batman Forever in June 1995, Warner Bros. immediately commissioned a sequel. They hired director Joel Schumacher and writer Akiva Goldsman to reprise their duties the following August, and decided it was best to fast track production for a June 1997 target release date, which is a break from the usual 3-year gap between films. Schumacher wanted to homage both the broad camp style of the 1960s television series and the work of Dick Sprang. The storyline of Batman & Robin was conceived by Schumacher and Goldsman during pre-production on A Time to Kill. Portions of Mr. Freeze's back-story were based on the Batman: The Animated Series episode ''Heart of Ice'', written by Paul Dini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–†–ê–í–ò–õ–ê\n",
    "1. –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –≥—Ä—É–ø–ø–µ –¥–æ 3-—Ö —á–µ–ª–æ–≤–µ–∫.\n",
    "2. –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ —Å–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ anytask, –∏–Ω–≤–∞–π—Ç—ã –±—É–¥—É—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–ª–∞–Ω—ã.\n",
    "3. –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –æ—Ñ–æ—Ä–º–ª—è–µ—Ç—Å—è –≤ –≤–∏–¥–µ –æ—Ç—á–µ—Ç–∞ –ª–∏–±–æ –≤ .pdf —Ñ–∞–π–ª–µ, –ª–∏–±–æ ipython-—Ç–µ—Ç—Ä–∞–¥–∫–µ. \n",
    "4. –û—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å: –Ω—É–º–µ—Ä–∞—Ü–∏—é –∑–∞–¥–∞–Ω–∏–π –∏ –ø—É–Ω–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏, –∫–æ–¥ —Ä–µ—à–µ–Ω–∏—è, –∏ –ø–æ–Ω—è—Ç–Ω–æ–µ –ø–æ—à–∞–≥–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤—ã —Å–¥–µ–ª–∞–ª–∏. –û—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞–ø–∏—Å–∞–Ω –≤ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–º —Å—Ç–∏–ª–µ, –±–µ–∑ –∏–∑–ª–∏—à–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–ª–µ–Ω–≥–∞ –∏ —Å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º –Ω–æ—Ä–º —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.\n",
    "5. –ù–µ —Å—Ç–æ–∏—Ç –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ª–µ–∫—Ü–∏–π, —Å—Ç–∞—Ç–µ–π –∏ –í–∏–∫–∏–ø–µ–¥–∏–∏ –≤ –≤–∞—à –æ—Ç—á–µ—Ç.\n",
    "6. –û—Ç—á–µ—Ç—ã, —Å–æ—Å—Ç–æ—è—â–∏–µ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –∏–∑ –∫–æ–¥–∞, –Ω–µ –±—É–¥—É—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –∏ –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–µ–Ω—ã –Ω—É–ª–µ–≤–æ–π –æ—Ü–µ–Ω–∫–æ–π.\n",
    "7. –ü–ª–∞–≥–∏–∞—Ç –∏ –ª—é–±–æ–µ –Ω–µ–¥–æ–±—Ä–æ—Å–æ–≤–µ—Ç—Å–Ω–æ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ–±–Ω—É–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import jsonlines\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "DATA_PREF = 'data/'\n",
    "os.makedirs(DATA_PREF, exist_ok=True)\n",
    "TRAIN_FILE_PATH = DATA_PREF + 'train.jsonl'\n",
    "DEV_FILE_PATH = DATA_PREF + 'dev.jsonl'\n",
    "FAST_TEXT_PREF = 'FastText/'\n",
    "os.makedirs(FAST_TEXT_PREF, exist_ok=True)\n",
    "FAST_TEXT_TRAIN_FILE_PATH = FAST_TEXT_PREF + 'train.txt'\n",
    "FAST_TEXT_DEV_FILE_PATH = FAST_TEXT_PREF + 'dev.txt'\n",
    "FAST_TEXT_MODEL_NAME = FAST_TEXT_PREF + 'model.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(file_path):\n",
    "    with jsonlines.open(file_path, 'r') as reader:\n",
    "        df = pd.DataFrame.from_records(list(reader))\n",
    "    df['passage'] = df['passage'].map(unidecode)\n",
    "    df['question'] = df['question'].map(unidecode)\n",
    "    df['title'] = df['title'].map(unidecode)\n",
    "    return df\n",
    "    \n",
    "df_train = open_dataset(TRAIN_FILE_PATH)    \n",
    "df_dev = open_dataset(DEV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–∞—Å—Ç—å 1. [1 –±–∞–ª–ª] –≠–∫—Å–ø–ª–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n",
    "1. –ü–æ—Å—á–∏—Ç–∞–π—Ç–µ –¥–æ–ª—é yes –∏ no –∫–ª–∞—Å—Å–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ\n",
    "2. –û—Ü–µ–Ω–∏—Ç–µ —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –≤–æ–ø—Ä–æ—Å–∞\n",
    "3. –û—Ü–µ–Ω–∏—Ç–µ —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞\n",
    "4. –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ, –ø–æ –∫–∞–∫–∏–º —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º –±—ã–ª–∏ —Å–æ–±—Ä–∞–Ω—ã –≤–æ–ø—Ä–æ—Å—ã (–∏–ª–∏ –Ω–∞–π–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç –≤ —Å—Ç–∞—Ç—å–µ). –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—É–π—Ç–µ, –∫–∞–∫ —ç—Ç–∏ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ—Ä–ø—É—Å–∞. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Persian (/'pe:rZ@n, -S@n/), also known by its ...</td>\n",
       "      <td>do iran and afghanistan speak the same language</td>\n",
       "      <td>Persian language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Good Samaritan laws offer legal protection to ...</td>\n",
       "      <td>do good samaritan laws protect those who help ...</td>\n",
       "      <td>Good Samaritan law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Windows Movie Maker (formerly known as Windows...</td>\n",
       "      <td>is windows movie maker part of windows essentials</td>\n",
       "      <td>Windows Movie Maker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>Powdered sugar, also called confectioners' sug...</td>\n",
       "      <td>is confectionary sugar the same as powdered sugar</td>\n",
       "      <td>Powdered sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>As with other games in The Elder Scrolls serie...</td>\n",
       "      <td>is elder scrolls online the same as skyrim</td>\n",
       "      <td>The Elder Scrolls Online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer                                            passage  \\\n",
       "0    True  Persian (/'pe:rZ@n, -S@n/), also known by its ...   \n",
       "1    True  Good Samaritan laws offer legal protection to ...   \n",
       "2    True  Windows Movie Maker (formerly known as Windows...   \n",
       "3    True  Powdered sugar, also called confectioners' sug...   \n",
       "4   False  As with other games in The Elder Scrolls serie...   \n",
       "\n",
       "                                            question                     title  \n",
       "0    do iran and afghanistan speak the same language          Persian language  \n",
       "1  do good samaritan laws protect those who help ...        Good Samaritan law  \n",
       "2  is windows movie maker part of windows essentials       Windows Movie Maker  \n",
       "3  is confectionary sugar the same as powdered sugar            Powdered sugar  \n",
       "4         is elder scrolls online the same as skyrim  The Elder Scrolls Online  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ–ª—è True –º–µ—Ç–æ–∫:\t\t\t\t 0.6231038506417736\n",
      "–î–æ–ª—è False –º–µ—Ç–æ–∫:\t\t\t\t 0.37689614935822635\n",
      "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞:\t\t\t\t 43.99204412856688 —Å–∏–º–≤–æ–ª–æ–≤\n",
      "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞:\t\t\t 565.7658852232948 —Å–∏–º–≤–æ–ª–æ–≤\n",
      "–î–æ–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö—Å—è —Å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: \t 0.9570382942611647\n"
     ]
    }
   ],
   "source": [
    "print('–î–æ–ª—è True –º–µ—Ç–æ–∫:\\t\\t\\t\\t', (df_train['answer'].values == True).mean())\n",
    "print('–î–æ–ª—è False –º–µ—Ç–æ–∫:\\t\\t\\t\\t', (df_train['answer'].values == False).mean())\n",
    "len_func = np.vectorize(lambda x: len(x))\n",
    "print('–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞:\\t\\t\\t\\t', len_func(df_train['question'].values).mean(), '—Å–∏–º–≤–æ–ª–æ–≤')\n",
    "print('–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞:\\t\\t\\t', len_func(df_train['passage'].values).mean(), '—Å–∏–º–≤–æ–ª–æ–≤')\n",
    "yes_no_words_set = set(['did', 'do', 'does', 'is', 'are', 'was', 'were', 'have', 'has', 'can', 'could', 'will', 'would'])\n",
    "is_in_set_func = np.vectorize(lambda x: x.split()[0].lower() in yes_no_words_set)\n",
    "print('–î–æ–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö—Å—è —Å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: \\t', is_in_set_func(df_train['question'].values).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–ø—Ä–æ—Å, –∑–∞–¥–∞–≤–∞–µ–º—ã–π –≥—É–≥–ª—É, –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª—Å—è –∫–∞–∫ \"yes/no question\", –µ—Å–ª–∏ –æ–Ω –Ω–∞—á–∏–Ω–∞–ª—Å—è —Å –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞. (—Å–ª–æ–≤–∞ –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ —è—á–µ–π–∫–µ –≤—ã—à–µ). –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, 95% –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –∏–º–µ–Ω–Ω–æ —Å –Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–∞—Å—Ç—å 2. [1 –±–∞–ª–ª] Baseline\n",
    "1. –û—Ü–µ–Ω–∏—Ç–µ accuracy —Ç–æ—á–Ω–æ—Å—Ç—å —Å–æ–≤—Å–µ–º –ø—Ä–æ—Å—Ç–æ–≥–æ –±–∞–∑–æ–≤–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è: –ø—Ä–∏—Å–≤–æ–∏—Ç—å –∫–∞–∂–¥–æ–π –ø–∞—Ä–µ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –≤ dev —á–∞—Å—Ç–∏ —Å–∞–º—ã–π —á–∞—Å—Ç—ã–π –∫–ª–∞—Å—Å –∏–∑ train —á–∞—Å—Ç–∏\n",
    "2. –û—Ü–µ–Ω–∏—Ç–µ accuracy —á—É—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–≥–æ –±–∞–∑–æ–≤–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è: fasttext –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö, —Å–æ—Å—Ç–æ—è—â–∏—Ö –∏–∑ —Å–∫–ª–µ–µ–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –∞–±–∑–∞—Ü–µ–≤ (' '.join([question, passage]))\n",
    "\n",
    "–ü–æ—á–µ–º—É fasttext –ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —ç—Ç–æ–π –∑–∞–¥–∞—á–µ–π?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –≤—Å–µ–º –º–µ—Ç–∫–∞–º True: 0.621713\n"
     ]
    }
   ],
   "source": [
    "y_true = df_dev['answer'].values\n",
    "y_pred = np.ones_like(y_true)\n",
    "print('–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –≤—Å–µ–º –º–µ—Ç–∫–∞–º True: %f' % (y_true == y_pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def write_to_fasttext_dataset(df, res_file_path):\n",
    "    f = open(res_file_path, 'w')\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        obj = df.iloc[i]\n",
    "        line = '__label__' + str(int(obj['answer'])) + ' '\n",
    "        line = line + obj['passage'] + ' ' + obj['question'] + '\\n'\n",
    "        f.write(line)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53dff36824242e692f86d02cd45b589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9427), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d186cc5d68b241048cdf81ffe541d118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3270), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_to_fasttext_dataset(df_train, FAST_TEXT_TRAIN_FILE_PATH)\n",
    "write_to_fasttext_dataset(df_dev, FAST_TEXT_DEV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found backup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_fasttext_model():\n",
    "    if os.path.exists(FAST_TEXT_MODEL_NAME) and os.path.isfile(FAST_TEXT_MODEL_NAME):\n",
    "        print('Found backup')\n",
    "        return fasttext.load_model(FAST_TEXT_MODEL_NAME)\n",
    "    model = fasttext.train_supervised(FAST_TEXT_TRAIN_FILE_PATH, label_prefix='__label__', epoch=400)\n",
    "    model.save_model(FAST_TEXT_MODEL_NAME)\n",
    "    return model\n",
    "\n",
    "fasttext_model = train_fasttext_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e60b2877a340bba28141344d9ecf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3270), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def make_input_fasttext(df):\n",
    "    inp = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        obj = df.iloc[i]\n",
    "        line = obj['passage'] + ' ' + obj['question']\n",
    "        inp.append(line)\n",
    "    return inp\n",
    "dev_fasttext_input = make_input_fasttext(df_dev)\n",
    "fasttext_prediction = fasttext_model.predict(dev_fasttext_input)[0]\n",
    "fasttext_prediction = np.array([int(s[0][len('__label__'):]) for s in fasttext_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6513761467889908\n"
     ]
    }
   ],
   "source": [
    "print((fasttext_prediction == y_true).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText –ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–∏–ª—Å—è, –ø–æ—Ç–æ–º—É —á—Ç–æ –∫–ª–∞—Å—Å—ã –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–∞—Å—Ç—å 3. [1 –±–∞–ª–ª] –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "1. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ BERT —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤–æ–ø—Ä–æ—Å–∞ –∏ –∞–±–∑–∞—Ü–∞. –û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö –≤–æ–ø—Ä–æ—Å–∞ –∏ –∞–±–∑–∞—Ü–∞ –∏ –æ—Ü–µ–Ω–∏—Ç–µ accuracy —ç—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è. \n",
    "\n",
    "[bonus] –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ ü§ó Transformers. –ö–∞–∫–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–∞—Å—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã?\n",
    "\n",
    "[bonus] –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –º–µ—Ç–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –µ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–∞—Å—Ç—å 3. [3 –±–∞–ª–ª–∞] DrQA-–ø–æ–¥–æ–±–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "\n",
    "–û—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Å—Ç–∞—Ç—å–µ: Reading Wikipedia to Answer Open-Domain Questions\n",
    "\n",
    "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes\n",
    "\n",
    "https://arxiv.org/abs/1704.00051\n",
    "\n",
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DrQA –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ SQuAD, –Ω–æ –ª–µ–≥–∫–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∫ —Ç–µ–∫—É—â–µ–º—É –∑–∞–¥–∞–Ω–∏—é. –ú–æ–¥–µ–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –±–ª–æ–∫–æ–≤:\n",
    "1. –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –∞–±–∑–∞—Ü–∞ [paragraph encoding] ‚Äì LSTM, –ø–æ–ª—É—á–∞—è—â–∞—è –Ω–∞ –≤—Ö–æ–¥ –≤–µ–∫—Ç–æ—Ä–∞ —Å–ª–æ–≤, —Å–æ—Å—Ç–æ—è—â–∏–µ –∏–∑: \n",
    "* —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å–ª–æ–≤–∞ (w2v –∏–ª–∏ fasttext)\n",
    "* –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, –∫–æ–¥–∏—Ä—É—é—â–∏—Ö –≤ –≤–∏–¥–µ one-hot –≤–µ–∫—Ç–æ—Ä–æ–≤ —á–∞—Å—Ç—å —Ä–µ—á–∏ —Å–ª–æ–≤–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–Ω–æ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç—å—é –∏–ª–∏ –Ω–µ—Ç, –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –≤ –≤–æ–ø—Ä–æ—Å–µ –∏–ª–∏ –Ω–µ—Ç \n",
    "* –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–∞, –ø–æ–ª—É—á–∞–µ–º–æ–≥–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º soft attention –º–µ–∂–¥—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ —Å–ª–æ–≤ –∏–∑ –∞–±–∑–∞—Ü–∞ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º –≤–æ–ø—Ä–æ—Å–∞.\n",
    "\n",
    "$f_{align}(p_i) = \\sum_jÙè∞Ç a_{i,j} E(q_j)$, –≥–¥–µ $E(q_j)$ ‚Äì —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–ª–æ–≤–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞. –§–æ—Ä–º—É–ª–∞ –¥–ª—è $a_{i,j}$ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –≤ —Å—Ç–∞—Ç—å–µ. \n",
    "\n",
    "2. –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –≤–æ–ø—Ä–æ—Å–∞ [question encoding] ‚Äì LSTM, –ø–æ–ª—É—á–∞—è—â–∞—è –Ω–∞ –≤—Ö–æ–¥ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞. –í—ã—Ö–æ–¥ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞: $q = Ùè∞Ç\\sum_jÙè∞Ç  b_j q_j$. –§–æ—Ä–º—É–ª–∞ –¥–ª—è $b_{j}$ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –≤ —Å—Ç–∞—Ç—å–µ. \n",
    "\n",
    "3. –°–ª–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. \n",
    "\n",
    "–ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ, –∫–∞–∫ –º–æ–∂–Ω–æ –±—ã–ª–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ DrQA, —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –∏—Ç–æ–≥–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ‚Äì¬†—ç—Ç–æ –º–µ—Ç–∫–∞ yes / no, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ—â–µ, —á–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ø–∞–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è SQuAD.\n",
    "\n",
    "–û—Ü–µ–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏. \n",
    "\n",
    "[bonus] –ó–∞–º–µ–Ω–∏—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤—Å–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞–º–∏, –Ω–∞ BERT —ç–º–±–µ–¥–¥–∏–Ω–≥–∏. –£–ª—É—á—à–∏—Ç –ª–∏ —ç—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–∞—Å—Ç—å 4. [3 –±–∞–ª–ª–∞] BiDAF-–ø–æ–¥–æ–±–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "\n",
    "–û—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Å—Ç–∞—Ç—å–µ: Bidirectional Attention Flow for Machine Comprehension\n",
    "\n",
    "Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi\n",
    "\n",
    "https://arxiv.org/abs/1611.01603\n",
    "\n",
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ BiDAF –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ SQuAD, –Ω–æ –ª–µ–≥–∫–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∫ —Ç–µ–∫—É—â–µ–º—É –∑–∞–¥–∞–Ω–∏—é. –ú–æ–¥–µ–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –±–ª–æ–∫–æ–≤:\n",
    "1. –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫  –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –¥–≤–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞: —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–ª–æ–≤–∞ –∏ –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ –∏–∑ CNN –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞. –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫–∏ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ –∏ –¥–ª—è –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã. \n",
    "2. –°–ª–æ–π –≤–Ω–∏–º–∞–Ω–∏—è (–¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–æ –≤ —Å—Ç–∞—Ç—å–µ, —Å–º. –ø—É–Ω–∫—Ç Attention Flow Layer)\n",
    "3. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤ –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞, —Å–æ—Å—Ç–æ—è—â–∏–µ –∏–∑ —Ç—Ä–µ—Ö —á–∞—Å—Ç–µ–π (–≤—ã—Ö–æ–¥ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞,   Query2Context (–æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä) –∏ Context2Query (–º–∞—Ç—Ä–∏—Ü–∞) –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è\n",
    "\n",
    "4. –°–ª–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. \n",
    "\n",
    "–ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ, –∫–∞–∫ –º–æ–∂–Ω–æ –±—ã–ª–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ BiDAF, —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –∏—Ç–æ–≥–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ‚Äì¬†—ç—Ç–æ –º–µ—Ç–∫–∞ yes / no, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ—â–µ, —á–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ø–∞–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è SQuAD.\n",
    "\n",
    "–û—Ü–µ–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏. \n",
    "\n",
    "[bonus] –ó–∞–º–µ–Ω–∏—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤—Å–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞–º–∏, –Ω–∞ BERT —ç–º–±–µ–¥–¥–∏–Ω–≥–∏. –£–ª—É—á—à–∏—Ç –ª–∏ —ç—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ DrQA –∏ BiDAF:\n",
    "    \n",
    "![](https://www.researchgate.net/profile/Felix_Wu6/publication/321069852/figure/fig1/AS:560800147881984@1510716582560/Schematic-layouts-of-the-BiDAF-left-and-DrQA-right-architectures-We-propose-to.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–∞—Å—Ç—å 5. [1 –±–∞–ª–ª] –ò—Ç–æ–≥–∏\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã. –°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ß—Ç–æ –ø–æ–º–æ–≥–ª–æ –≤–∞–º –≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã, —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–ª–æ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
